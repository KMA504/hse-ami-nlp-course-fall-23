{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cDlh5WB_SkfZ"
   },
   "source": [
    "# Домашнее задание 1\n",
    "## Sentiment Analysis in English\n",
    "\n",
    "*deadline*: 1 октября 2023, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусом новостных текстов на английском языке. Корпус собран из заметок новостных сайтов с указанием на тональность данного текста.\n",
    "\n",
    "Корпус описан и представлен по ссылке: https://www.kaggle.com/datasets/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n",
    "Части 1, 2 задания должны быть выполнены на полных текстах, Часть 3 – на разбиении на тестовое, отладочное и обучающее множества (которое вы должно произвести самостоятельно). Тестовое множество должно быть использовано исключительно для тестирования моделей, обучающее и отладочное – для выбора модели и параметров. \n",
    "\n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 4-х человек.\n",
    "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо jupyter-тетрадке. \n",
    "3. Отчет должен содержать: имена всех членов группы, нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "6. Плагиат и любое недобросовестное цитирование приводит к обнулению оценки. \n",
    "7. За каждую неделю просрочки после дедлайна начисляет по 1 штрафному баллу (например, при дедлайне 01.10.23 в 23:59 сдача ДЗ 12.10.22 ведёт к 2 штрафным баллам). \n",
    "\n",
    "\n",
    "## Часть 1. [2 балла] Эксплоративный анализ \n",
    "1. Найдите топ-300 слов по частоте без учета стоп-слов.\n",
    "2. Найдите топ слов, характеризующих каждую тональность отдельно. \n",
    "\n",
    "[бонус] Постройте тематическую модель по данному корпусу.\n",
    "\n",
    "[бонус] Найдите еще что-то интересное в корпусе (что-то специфичное для данной темы)\n",
    "\n",
    "## Часть 2. [2 балла] Модели представления слов \n",
    "Обучите модель представления слов (word2vec, GloVe, fastText или любую другую) на материале корпуса.\n",
    "1. Продемонстрируйте, как работает поиск синонимов, ассоциаций, лишних слов в обученной модели. \n",
    "2. Визуализируйте топ-300 слов по частоте без учета стоп-слов (п. 1.1) с помощью TSNE или UMAP (https://umap-learn.readthedocs.io).\n",
    "\n",
    "## Часть 3. [5 баллов] Классификация текстов\n",
    "Задача классификации формулируется так: каждая новостная статья описывает какую-то ситуацию, имеющую определенную тональность. Требуется по тексту предсказать, какую тональность имеет данная статья. Таким образом, тональность - это фактически метка класса. Основная мера качества – macro $F_1$.\n",
    "Обучите несколько классификаторов и сравните их между собой. Оцените качество классификаторов на каждом из классв. Какие классы чаще всего оказываются перепутаны? Связаны ли ошибки со смыслом текстов?\n",
    "\n",
    "Используйте фрагменты из множества train для обучения, из множества dev для отладки, из множества test – для тестирования и получения итоговых результатов. \n",
    "\n",
    "1. [1 балл] Используйте fastText в качестве baseline-классификатора.\n",
    "2. [2 балла] Используйте сверточные сети в качестве более продвинутого классификатора. Поэкспериментируйте с количеством и размерностью фильтров, используйте разные размеры окон, попробуйте использовать $k$-max pooling. \n",
    "3. [2 балла] Попробуйте расширить обучающее множество за счет аугментации данных. Если вам понадобится словарь синонимов, можно использовать WordNet (ниже вы найдете примеры).\n",
    "\n",
    "[бонус] Используйте результат max pooling'а как эмбеддинг входного текста. Визуализируйте эмбеддинги 300-500 предложений из обучающего множества и изучите свойства получившегося пространства.\n",
    "\n",
    "[бонус] Используйте ваш любимый классификатор и любые (честные) способы повышения качества классификации и получите macro $F_1$ больше 0.5.\n",
    "\n",
    "## Часть 4. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Обобщите все полученные вами результаты и сделайте выводы."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-17Rx31xSkfh"
   },
   "source": [
    "### Данные\n",
    "Сырые тексты "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "09cqK5nbSkfo",
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "!unzip sentiment-analysis-in-russian.zip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lUhi0n1-Skg8"
   },
   "source": [
    "train, test, dev файлы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RNK9lk9RSkg_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_json('train.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "37fRsFqOSkhT"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bcfq1-dNSkho"
   },
   "outputs": [],
   "source": [
    "df.iloc[0]['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CKFkwT8USkh_"
   },
   "source": [
    "### Как использовать WordNet из nltk?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4iQMTFSSkiD"
   },
   "outputs": [],
   "source": [
    "# скачиваем WordNet\n",
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b-vJu2zsSkiU"
   },
   "outputs": [],
   "source": [
    "# слово -> множество синсетов (синонимов разных смыслов исходного слова)\n",
    "from nltk.corpus import wordnet as wn\n",
    "wn.synsets('magic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nI2PFixLSkip"
   },
   "outputs": [],
   "source": [
    "# посмотрим, что внутри одного синсета\n",
    "wn.synsets('magic')[1].lemmas()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPLmJrrjSki5"
   },
   "outputs": [],
   "source": [
    "# возьмем лемму одного из слов из синсета\n",
    "wn.synsets('magic')[1].lemmas()[-1].name()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
