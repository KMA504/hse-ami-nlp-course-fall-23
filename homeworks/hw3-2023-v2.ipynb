{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RZY7kcPjTtIk"
   },
   "source": [
    "# Домашнее задание 3\n",
    "## Named Entity Recognition\n",
    "\n",
    "deadline: 3 декабря 2023, 23:59\n",
    "\n",
    "В этом домашнем задании вы будете работать с корпусами - BiodivNER и COPIOUS.\n",
    "Эти корпуса собраны из открытых источников по теме биооразнообразия и вручную размечены экспертами.\n",
    "\n",
    "Корпусы описан в статьях:\n",
    "https://bdj.pensoft.net/article/89481/\n",
    "https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6351503/\n",
    "\n",
    "BiodivNER\n",
    "Корпус доступен в репозитории проекта:  https://github.com/fusion-jena/BiodivNERE (вам нужен именно NER).\n",
    "https://zenodo.org/records/6458503\n",
    "Также в этом репозитории есть код для корректного создания набора данных из корпуса.\n",
    "\n",
    "COPIOUS\n",
    "Корпус приложен к статье https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6351503/ в разделе Supplementary material 2\n",
    "\n",
    "Статья и код, использованный для извлечения именованных сущностей: \n",
    "* Meizhi Ju, Makoto Miwa and Sophia Ananiadou, A Neural Layered Model for Nested Named Entity Recognition, https://github.com/meizhiju/layered-bilstm-crf\n",
    "\n",
    "\n",
    "В корпусе BiodivNER используются 6 типов именованных сущностей: ORGANISM (e.g. plants, fungi, bacteria), ENVIRONMENT (environments species live in), QUALITY (characteristics to be measured), MATERIAL (e.g. chemical compounds), PROCESS (re-occurring biological and physical processes), LOCATION (geographic location) and DATA TYPE (research results, e.g. lidar data), допускаются вложенные сущности. \n",
    "\n",
    "В корпусе COPIOUS используются 5 типов именованных сущностей: Geographical Location, Person, Temporal Expression, Taxon, Habitat, допускаются вложенные сущности. \n",
    "\n",
    "В статьях и репозиториях вы найдете идеи, которые помогут вам выполнить домашнее задание. Их стоит воспринимать как руководство к действию, и не стоит их копировать и использовать повторно. Обученные модели использовать не нужно, код для их обучения можно использовать как подсказку. \n",
    "\n",
    "## ПРАВИЛА\n",
    "1. Домашнее задание выполняется в группе до 4-х человек.\n",
    "2. Домашнее задание оформляется в виде отчета либо в .pdf файле, либо в ipython-тетрадке. При этом прикладывать ipynb-файл обязательно. \n",
    "3. Отчет должен содержать: нумерацию заданий и пунктов, которые вы выполнили, код решения, и понятное пошаговое описание того, что вы сделали. Отчет должен быть написан в академическом стиле, без излишнего использования сленга и с соблюдением норм русского языка.\n",
    "4. Не стоит копировать фрагменты лекций, статей и Википедии в ваш отчет.\n",
    "5. Отчеты, состоящие исключительно из кода, не будут проверены и будут автоматически оценены нулевой оценкой.\n",
    "6. Плагиат и любое недобросовестное цитирование приводит к обнулению оценки. \n",
    "\n",
    "\n",
    "## Часть 1. [1.5 балла] Эксплоративный анализ \n",
    "1. [0.5 балла] Найдите топ (по частоте) именованных сущностей каждого из типов для каждого корпуса. Произведите сравнение частотности по совпадающим сущностям при сопоставлении корпусов друг с другом.\n",
    "2. [0.5 балла] На основе частотного и логического анализа сопоставьте сущности между корпусами (одной сущности первого корпуса может соответствовать несколько сущностей второго корпуса и наоборот).\n",
    "3. [0.5 балла] Осуществить проверку результата вашего сопоставления на основе некоторой модели векторизации слов английского языка. Если будет выичслительно трудно это проверять на всем корпусе, то можно сделать на подвыборке.\n",
    "\n",
    "В следующих частях домашнего задания вам понадобится train-test-dev разбиения. Стратификация уже произведена в корпусах в соотношении 80%:10%:10%, ей и воспользуйтесь.\n",
    "\n",
    "\n",
    "## Часть 2. [5 баллов] Извлечение именованных сущностей\n",
    "Для каждой корпуса необходимо осуществить раздельно следующую процедуру:\n",
    "1. [1 балл] Обучите стандартную модель для извлечения именованных сущностей, CNN-BiLSTM, для извлечения именованных *низкоуровневых именованных сущностей*, т.е. для самых коротких из вложенных сущностей. Модель устроена так: сверточная сеть на символах + эмбеддинги слов + двунаправленная LSTM сеть (модель последовательности).\n",
    "\n",
    "бонусный вариант:\n",
    "Обучите стандартную модель для извлечения именованных сущностей, CNN-BiLSTM-CRF, для извлечения именованных *низкоуровневых именованных сущностей*, т.е. для самых коротких из вложенных сущностей. Модель устроена так: сверточная сеть на символах + эмбеддинги слов + двунаправленная LSTM сеть (модель последовательности) + CRF (глобальная нормализация).\n",
    "2. [1 балл] Замените часть модели на символах и словах (CNN + эмбеддинги словах) на RoBERTa.\n",
    "3. [3 балла] Замените модель последовательности (BiLSTM) на другой слой, например, на Transformer.\n",
    "\n",
    "В результате у вас будет 2 набора моделей - проверьте качество извлечения на тестовых данных.\n",
    "- Примените модели первого корпуса ко всем (!!!) предложениям второго корпуса и наоборот.\n",
    "- Составьте отчёт по качеству работы моделей в терминах извлечения сущностей на основе мэппинга, который вы сделали в Части 1. Метрику выберите самостоятельно.\n",
    "- Проанализируйте ошибки моделей в терминах предсказания сущностям первого корпуса специфических типов для второго корпуса. И наоборот - когда специфическим типам второго корпуса модель, обученная на первом, присваивает одну из своих категорий.\n",
    "\n",
    "[бонус] Дообучите BERT для извлечения именованных сущностей.\n",
    "\n",
    "[бонус] Используйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018]\n",
    "\n",
    "[бонус] Модифицируйте модель для извлечения вложенных именованных сущностей [Ju et al., 2018]: вместо эмбеддингов слов используйте BERT. \n",
    "\n",
    "## Часть 3. [2.5 балла] Извлечение локаций \n",
    "\n",
    "1. [0.75 балла] Используйте BiLSTM на эмбеддингах слов для извлечения географических локаций (на основе COPIOUS). \n",
    "\n",
    "2. [1.25 балла] Замените часть модели на словах на RoBERTa. Должна получиться модель RoBERTa + BiLSTM.\n",
    "\n",
    "3. [0.5 балла] Проверьте \"извлекающую\" силу модели на данных BiodivNER для событий типа Location. \n",
    "\n",
    "[бонус] Предобучите BiLSTM как языковую модель. Дообучите ее для извлечения локаций. \n",
    "\n",
    "[бонус] Дообучите BERT для извлечения локаций. \n",
    "\n",
    "## Часть 4 (бонусная). Одновременное извлечение локаций и организмов\n",
    "1. [0.75 бонуса] Обучите модель для совместного извлечения локаций и организмов только на основе BiodivNER (!). У модели должен быть общий энкодер (например, CNN + BiLSMT, ELMo + BiLSTM, BERT + BiLSTM) и два декодера: один отвечает за извлечение именованных сущностей, другой отвечает за извлечение триггеров событий.\n",
    "\n",
    "2. [0.75 бонуса] Создайте единую обучающую подвыборку, единую валидационную и единую тестовую на основе разбиений, которые были вам предоставлены и обучите модель. (Единую - то есть на основе обоих корпусов сразу)\n",
    "\n",
    "3. [0.5 бонуса] Сравните предсказательную силу модели из п.1 и модели из п.2 как на совместных подвыборках, так и на раздельных. Проанализируйте полученный результат. Приводит ли обогащение дополнительными данными к улучшению \"извлекающей\" способности модели?\n",
    "\n",
    "[бонус] Добавьте в модель механизм внимания, таким способом, который покажется вам разумным.\n",
    "\n",
    "[бонус] Визуализируйте карты механизма внимания (attention). \n",
    "\n",
    "## Часть 5. [1 балл] Итоги\n",
    "Напишите краткое резюме проделанной работы. Сравните результаты всех разработанных моделей. Что помогло вам в выполнении работы, чего не хватало?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "hw2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
